{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e723b8f-2934-4df2-961a-bff24c92e613",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "+ Spotify Music dataset is collected from the following link\n",
    "https://www.kaggle.com/datasets/notshrirang/spotify-million-song-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca0a338-657d-49b7-b555-89c3fafdd251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3653499-8f59-4518-a953-581404195a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\r\\nA...  \n",
       "1  Take it easy with me, please  \\r\\nTouch me gen...  \n",
       "2  I'll never know why I had to go  \\r\\nWhy I had...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/hanzilasohan/Music Recommendation App/spotify_millsongdata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d6f922-22bb-47ef-acb1-6e92a76dd7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57650, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e12f4a-2d82-4710-80ca-49811d621e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist    0\n",
       "song      0\n",
       "link      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b9a03d-96fd-445e-88ed-3b5ac1b05d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(5000).drop('link',axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6474d509-6280-451b-87da-482342058e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W.A.S.P.</td>\n",
       "      <td>I Don't Need No Doctor</td>\n",
       "      <td>I don't need no doctor  \\r\\n'Cause I know what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob Seger</td>\n",
       "      <td>Long Song Comin'</td>\n",
       "      <td>Politician 'bout to make his speech  \\r\\nSigna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Venom</td>\n",
       "      <td>Mystique</td>\n",
       "      <td>Mystique our majesty, Goddess unwind  \\r\\nMyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guns N' Roses</td>\n",
       "      <td>One In A Million</td>\n",
       "      <td>Yes I needed some time to get away  \\r\\nI need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hanson</td>\n",
       "      <td>Love Song</td>\n",
       "      <td>The wind--it blows through the trees  \\r\\nClai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                    song  \\\n",
       "0       W.A.S.P.  I Don't Need No Doctor   \n",
       "1      Bob Seger        Long Song Comin'   \n",
       "2          Venom                Mystique   \n",
       "3  Guns N' Roses        One In A Million   \n",
       "4         Hanson               Love Song   \n",
       "\n",
       "                                                text  \n",
       "0  I don't need no doctor  \\r\\n'Cause I know what...  \n",
       "1  Politician 'bout to make his speech  \\r\\nSigna...  \n",
       "2  Mystique our majesty, Goddess unwind  \\r\\nMyst...  \n",
       "3  Yes I needed some time to get away  \\r\\nI need...  \n",
       "4  The wind--it blows through the trees  \\r\\nClai...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca32a97-b6cc-4aac-ac80-442ef1d88aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(10000)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f25893-7665-4719-ab51-20d276d5b771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't need no doctor  \\r\\n'Cause I know what's ailing me  \\r\\nI don't need no doctor  \\r\\n'Cause I know what's ailing me (yes, I do)  \\r\\nAll I need is my baby  \\r\\nYou don't know I'm in misery  \\r\\n  \\r\\nI don't need no doctor  \\r\\nI don't need no doctor  \\r\\n  \\r\\nI don't need no doctor  \\r\\nMy prescription tells me that  \\r\\nI don't need no doctor  \\r\\nMy prescription tells me that  \\r\\nAll I need is my baby  \\r\\nYou don't know I'm in misery  \\r\\n  \\r\\nI don't need no doctor  \\r\\nI don't need no doctor  \\r\\nI don't need no doctor  \\r\\nI don't need no doctor  \\r\\n  \\r\\nWell, the doctor said I need rest - ooh, ooh  \\r\\nHe put me on the critical list - ooh, ooh  \\r\\nKeeping me safe from harm - ooh, ooh  \\r\\nAll I need is her sweet charm - ooh, ooh  \\r\\nHe gave me a medical lotion, that  \\r\\nwouldn't do  \\r\\nOoh - yeah, my motion, oh yeah, no  \\r\\ndoctor no !  \\r\\n  \\r\\nI don't need no doctor  \\r\\nI don't need no doctor  \\r\\nI don't need no doctor  \\r\\nI don't need no doctor  \\r\\n  \\r\\nI don't need no doctor  \\r\\nI don't need no doctor  \\r\\nI don't need no doctor  \\r\\nI don't n\\r\\n\\r\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498dc80-c648-4379-a112-58d3850f8e44",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "+  Clean and preprocess the text by removing special characters, punctuation, and converting all letters to lowercase.\n",
    "+  Tokenize the descriptions into individual words or phrases.\n",
    "+  Remove stopwords (common words like \"and,\" \"the,\" \"is,\" etc.) that don't provide much context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2cf9520-ccaf-476f-bbb8-fbbb1c63bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower().replace(r'^\\w\\s',' ',regex=True).replace(r'\\n',' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c643feb4-1add-4ede-ba08-dadb971ff7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" don't need no doctor  \\r 'cause i know what's ailing me  \\r i don't need no doctor  \\r 'cause i know what's ailing me (yes, i do)  \\r all i need is my baby  \\r you don't know i'm in misery  \\r   \\r i don't need no doctor  \\r i don't need no doctor  \\r   \\r i don't need no doctor  \\r my prescription tells me that  \\r i don't need no doctor  \\r my prescription tells me that  \\r all i need is my baby  \\r you don't know i'm in misery  \\r   \\r i don't need no doctor  \\r i don't need no doctor  \\r i don't need no doctor  \\r i don't need no doctor  \\r   \\r well, the doctor said i need rest - ooh, ooh  \\r he put me on the critical list - ooh, ooh  \\r keeping me safe from harm - ooh, ooh  \\r all i need is her sweet charm - ooh, ooh  \\r he gave me a medical lotion, that  \\r wouldn't do  \\r ooh - yeah, my motion, oh yeah, no  \\r doctor no !  \\r   \\r i don't need no doctor  \\r i don't need no doctor  \\r i don't need no doctor  \\r i don't need no doctor  \\r   \\r i don't need no doctor  \\r i don't need no doctor  \\r i don't need no doctor  \\r i don't n\\r \\r \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dc124d1-a155-4a62-8034-c4db7a53f9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     don't need no doctor  \\r 'cause i know what's...\n",
       "1    politician 'bout to make his speech  \\r signal...\n",
       "2    mystique our majesty, goddess unwind  \\r mysti...\n",
       "3    yes i needed some time to get away  \\r i neede...\n",
       "4    the wind--it blows through the trees  \\r claim...\n",
       "5    \"beautiful reality\"  \\r   \\r i sometimes belie...\n",
       "6    oh, to be prince caspian afloat upon the waves...\n",
       "7    this is the rags to riches story  \\r of the in...\n",
       "8     enter your life now make no mistake  \\r can y...\n",
       "9    all night long  \\r hollywood  \\r all night lon...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38ad4b-35b3-40b2-94b4-e7baef5eb58c",
   "metadata": {},
   "source": [
    "# Tokenization (NLTK)\n",
    "+ Convert the tokenized descriptions into numerical representations that can be used by machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9a2e4c0-097c-4c45-8f5b-e88ba6dae56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97d20c0-6e7d-4c61-98af-4fdd48027c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "def826b1-fdc2-45ce-8d34-86a1676596a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f367256-bf6d-468a-a495-53b3d7147ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(txt):\n",
    "    token = nltk.word_tokenize(txt)\n",
    "    a =[stemmer.stem(w) for w in token]\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dec2b70-4a97-49ab-b25f-1db1db8dc6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you are beauti , beauti'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token(\"you are beautiful, beauty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed16e435-b980-4ecc-abb6-98f11a6bdd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1a12521-7d23-4dfe-83a9-9526c733e1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       do n't need no doctor 'caus i know what 's ail...\n",
       "1       politician 'bout to make hi speech signal for ...\n",
       "2       mystiqu our majesti , goddess unwind mystiqu o...\n",
       "3       ye i need some time to get away i need some pe...\n",
       "4       the wind -- it blow through the tree claim tho...\n",
       "                              ...                        \n",
       "4995    am on a lone road and i am travel travel , tra...\n",
       "4996    when i 'm walk besid her , peopl tell me i 'm ...\n",
       "4997    you may not recal the moment that you ask me b...\n",
       "4998    you give me life like lot of oxygen you treat ...\n",
       "4999    he got here and wrinkl scare and cryin ' the s...\n",
       "Name: text, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14488b-5f18-4340-8bb1-952e975bf8e4",
   "metadata": {},
   "source": [
    "# Vectorization(TF IDF)\n",
    "+  We can use techniques like TF-IDF (Term Frequency-Inverse Document Frequency) or word embeddings (Word2Vec, GloVe) for this purpose.\n",
    "# Content-Based Filtering\n",
    "+ one In our case, content-based filtering might be more suitable since we're focusing on analyzing the music lyrics(text). This approach recommends items similar to those the user has shown interest in.\n",
    "+ two Calculate similarity scores between musics based on their preprocessed music lyrics(texts)\n",
    "+ three Recommend musics that have similar descriptions to the ones the user has liked or interacted with in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1287909-72cf-4ece-96ce-cd1055b52bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7caa660-4610-4bd6-aba5-011057dffa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(analyzer='word',stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d1105de-975e-49e0-9f0a-61997066c05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tfid.fit_transform(df['text']).toarray()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fccfc32-55f8-4a36-946a-f76ed115e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simillar = cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebb7265b-0946-4b63-b5ae-b83c140677e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.00613287, 0.00178438, ..., 0.00652026, 0.00111279,\n",
       "       0.02178839])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simillar[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d32c7cd-596c-4b46-b99b-ff38e6f81669",
   "metadata": {},
   "source": [
    "# Create Recommender Function\n",
    "+ This function is created in a way so that users can search for a song by the song's name. The function will return a list of similar songs for any chosen song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e89e91e5-9d3a-4016-bb99-95d953d8a808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['song']==\"Love Song\"].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7a25c0a-2204-4ff5-8780-7db47a35db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(song_name):\n",
    "    idx = df[df['song']==song_name].index[0]\n",
    "    distance = sorted(list(enumerate(simillar[idx])), reverse=True, key=lambda x:x[1])\n",
    "    song=[]\n",
    "    for song_id in distance[1:8]:\n",
    "        song.append(df.iloc[song_id[0]].song)\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de8cd949-8198-4550-a0a6-ce27e6072840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"There's Nothing Better Than Love\",\n",
       " 'Do You Love Me That Much',\n",
       " 'Who Do You Love',\n",
       " 'Lifelong Passion',\n",
       " 'Angel',\n",
       " 'I Want Your Love',\n",
       " 'Like You Do']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender(\"Love Song\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8534a69f-d61b-4076-ae14-e728c099f5ab",
   "metadata": {},
   "source": [
    "# Store it in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7367b005-82a5-4ef1-82cb-b2e560ba9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c1de50f-2a88-457d-91f8-cc0bca68db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(simillar, open(\"similarity\",\"wb\")) #store my simillar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de501850-e003-47e6-9f74-5e6392871d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open(\"df\",\"wb\")) #store my dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea6c23-8bb4-4baf-a558-bcb29e113c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
